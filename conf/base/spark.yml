# You can define spark specific configuration here.

spark.driver.maxResultSize: 3g
spark.hadoop.fs.s3a.impl: org.apache.hadoop.fs.s3a.S3AFileSystem
spark.sql.execution.arrow.pyspark.enabled: true

spark.scheduler.mode: FAIR
# spark.sql.extensions: io.delta.sql.DeltaSparkSessionExtension
# spark.sql.catalog.spark_catalog: org.apache.spark.sql.delta.catalog.DeltaCatalog
# spark.jars.packages: org.apache.hadoop:hadoop-azure:3.3.1,org.apache.hadoop:hadoop-client:3.3.1,com.microsoft.azure:azure-storage:8.6.6,io.delta:delta-core_2.12:2.2.0
spark.jars: /workspace/conf/base/postgresql-42.5.1.jar
fs.azure.account.auth.type: OAuth
fs.azure.account.oauth.provider.type: org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider
fs.azure.account.oauth2.client.id: 3bd04c8f-ffed-4594-9cc7-dae3adfc076c
fs.azure.account.oauth2.client.secret: UP38Q~cbpDgw~q4urXklevs1qoo.FkRoE_dYFaFU
fs.azure.account.oauth2.client.endpoint: https://login.microsoftonline.com/374f8026-7b54-4a3a-b87d-328fa26ec10d/oauth2/token
spark.driver.bindAddress: 127.0.0.1
spark.driver.host: localhost
spark.master: local[*]